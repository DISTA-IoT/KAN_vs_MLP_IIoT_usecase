# Reti Kolmogorov Arnold e Multilayer Perceptron: Un Confronto Sperimentale

# Introduzione

# Reti MLP
Un MLP (Multilayer Perceptron) è una rete neurale feedforward che rappresenta una delle architetture di base nel deep learning. È progettato per apprendere funzioni non lineari complesse attraverso una serie di strati di neuroni completamente connessi.
Una rete MLP è composta fondamentalmente da tre tipologie di layer: un input layer, un output layer e un numero arbitrario di hidden layer che si trovano tra l'input e l'output layer. 
I neuroni che si trovano in strati adiacenti sono completamente collegati tra loro. Ogni connessione ha un peso associato, che determina la forza della connessione. Un peso elevato significa una forte connessione, mentre un peso basso o negativo indica una connessione debole o inibitoria. 

# Reti KAN

# Contenuti della Repository
**`/Power Consuption`**: Directory che contiene il dataset PowerConsuption e l'addestramento delle reti KAN  e MLP su questo dataset.

**`/Train Delay`**: Directory che contiene il dataset Train Delay e l'addestramento delle reti KAN  e MLP su questo dataset.

**`requirements.txt`**: File contenente le dipendenze Python necessarie per eseguire il progetto, che possono essere installate con `pip`.
